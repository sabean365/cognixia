
		
**Goal of SREs is to enable the product teams to move as fast as practically possible without impacting users.
	
	TALK-->	
	User having issues with your service -
		What is the issue?
		How do we know if something went wrong?
		What went wrong?
		What action to take?
		How to prevent these from occurring in the future?
		
	AVAILABILITY
	Definition varies
		% Uptime
		% Requests served
		
	PATH TOWARDS HIGH AVAILABILITY
		Add redundanccy N+2
			More replicas - webservers, database
			load balancers - distribution
		Write more tests: integration tests
		More humans ro respond to pagers
		Maintain checklist of possible bugs, and run through the list for each release
		Reduce release velocity
			Release one feature at a time
			Release a binary only after exhaustive automated and human testing
				
			New features
			feature + abcd
			developer transform -> ideas -> code
			operation = server 50gb 32CPU
			
			manufacturing issues
			logistics
			too many requests for product
			customer may not like feature
			bug -> finger print -> reported across the globe
			
			3.8
			
			quality = 
			
			release -> new phone 
			bug fix release -> emergency fix 
			
			6 month -> push update ->
			Update doesn't work -> roll back to previous version
			
			
			I want my app to be available ___
			
			Depends 
			Trade-off on launch velocity and system stability
				feature with low availability would be unusable - always broken
				feature with high availability would be unusable - very boring, features missing
			
			Deciding on right availability target
				Infrastructure (shared service) vs user-facing service
				Mature vs New product
				paid or free
				high revenue impact vs low
			
				Logical cost-benefit analysis.
				
			AVAILABILITY
				Service Level Indicators
					Metrics that matter: 
					- latency 
					- throughput (number of requests processed per second) 
					- Error Rate: % of requests answered
					IT IS IMPORTANT THAT THESE METRICS ARE CLEARLY DISCUSSED AND MUTUALLY AGREED UPON
					
				Service Level Objectives
					Latency - 300ms
					Hard to define SLOs for some metrics
					In those cases
						It is important to have a hard upper limit
				
				 - Expected downtime calculations
					99% 4 days dt
					99.9% 9 hours dt
					99.99% 1 hour dt
					99.999% 5 min of dt
					
				 - Error budget
					Target availability 99.9%
					The service has gained some error budget
				
				- Reliable only up to the defined limit, no more
					Sometimes, systems may give false impression of being over-reliable
					Leads other teams to build with false assumptions
					Extreme measure - Planned dt
					
				Planned downtime is used for error handling
			
			Abnormality Detection
				Monitoring
				Without monitoring - no way to know if system is working - predict a future issue, is not at all possible
				Good monitoring
					Enables analysis of long-term trends
					Enables comparative analysis
					Enables conductin ad hoc analysis - latency shot up, what else changed?
				NEVER REQUIRES A HUMAN TO INTERPRET AN ALERT
					Humans add latency
					Alert fatigue
					Ignore, if alarms are usually false
				3 KINDS OF MONITORING OUTPOUT
					Alert: Ture alarm - red alert. Human needs to take action.
					Ticket: Alarm - yellow alert. Human neesd to take action eventually
					Logging: Not an alarm - no action needed
					
					Logstash - Sumo 
					
					types of monitoring 
						black box - (user level) mimics a system user and shows how your users view your systems
						white box - (high level) viewing your system from the inside, for e.g. each service keeps counters of all backend service failures, latency
							in terms of qps, peak, num_shards, backend_latency
				
				Life of an Incident
					Report (log) the incident -> creates ticket 
					10 users get error - monitoring system kicks in SEnds a pager to oncall SRE
					In this case, black box monitoring kicked off an alert - after the fact alert
					
					white box monitoring can help predict and issue is about to happen + good centralized logging system used by ALL SERVERS
						plays big role in figuring out the origin of the problem
						allows SRE to discover where the issue is located - find underlying broken service causing the issue
						gives solution by consulting playbook (documented remediation) of underlying service and finding out how to disable feature
		
		
		MONITORING -> ->
					
		GUI - DASHBOARD
			
		SERVERS Application service 
			WEBSERVERS
			APP SERVER 
			DB SERVER
			
			THRESHOLD = 80%
			WHEN BREACH -> ALERTING MECHANISM -> ALL TEAM MEMBERS
			WHEN THRESHOLD REACHES 90$ -> ALERT -> CRITICAL -> LOG THE ISSUE -> TICKETING TOOL -> TICKET GOES TO PARTICULAR TEAM
			SERVUCES: WEB SERVER - CPU, Memory, Disk, Network
				
			SRE MONITORING PROCESS	
			SELECT MONITORING TOOL -> INTEGRATE WITH THE SYSTEM -> BENCHMARK THRESHOLD -> LATENCY/DOWNTIME -> STTP 200 (GOOD) STTP 400 - 500 (ISSUE) -> ALERTS/NOTIFICATION -> INTEGRATE THE TICKETING TOOL -> LOG IN TICKET OR TICKET IS AUTOMATICALLY LOGGED
			
			If 80% threshold is reached -> log in -> top command in Linux -> discover process that is causing high threshold -> ticket or alert owner of the issue
			
		IN SUMMARY
			Playbooks: guide to turning off features, feature flag names and descriptions
			Mean time to failure (MTTF) amount of time to record issue
			Mean time to recovery (MTTR) amount of time to fix
			"Dependency means single point of failure."		
			
		Release Mgmt: Progressive Rollouts - release cycle (such as one release per month)
			Software delivery -> release new feature
			
			Canary servers - a few production instances serving traffic from new binary
			Canary for sufficient time - Give the new binary some time to experience all posssible use cases
			Canary become prod on green
			Changes be backward compatible with 2-3 releases - Binaries can be safely rolled back (to blue)
			Two servers with old version and two servers with new version. If green (new) fails, revert to blud (previous).
			
			The basic steps of a canary deployment are:
				1. Deploy to one or more canary servers.
				2. Test, or wait until satisfied.
				3. Deploy to the remaining servers.
			
			No-blame postmortem
				Teams write detailed postmortem AFTER resolving outages
				Not attributed to any single person / team
				Structure
					What went wrong?
					What was the immediate fix?
					What is long term fix?
					What can we do to prevent it occurring in the future?
					
			Catastrophe Testing
				Test to break the system
				
				
			Possible scenarios of web traffic
				- Users per day: 100
				- Business and non-business hours
				- Peak hours
				- Flash sale
				- 50% offers
			
			Stress test for 5000 at once
				Bring down a few machines
				Network connectivity
			
		SUMMARY OF SRE WORK
			Decide on what metrics to measure and target values
			Monitor user facing and internal metrics
			Alert only when necessary
			Plan for failure mgmt - dashboards, playbooks and uniform logging
			Avoid a culture of heros
			Learn from failures
				
	DevOps

**Site Reliability Engineering
	
	business requirement -> analyze -> coding
	
	Development			<---------->	Operation
	
	Developer -> App					Operate and maintain the application
	
					load balance
													
	Domain -> host						Server1 - host application			Server2 - host 
	operate and maintain				  	second copy of code
	the application
	AWS
	Deploy the updated code
	
Context: Launching a new feature vs reliability
	Product Teams want to move fast
		Deploy as many features as possible
		Deploy as fast as possible
	Reliability Teams want to be stable
		Focus on reliability
		Break as little as possible
		
		
**DevOps is a collaboration between Development and IT Operations to make software production and deploymnet in an automated and repeatable way

	Development - Teamwork and Innovation
	
		++
	Ops  - Automation and Collaboration

WHY DevOps?
	Combination of Technology, Process and Culture
	
	
DevOps Models
	Left to Right Approach - Developer -> GIT -> Build Code/Unit Testing -> Artifacts -> Dev -> QA Test -> Pre-Production -> Production
	Right to Left approach -> continuous feedback from end user perspective
	Continuous Learning and Experimentation
	
Continuous Integration in DevOps - check in once a day

Continuous Deployment - putting all changes to production environmnet making sure changes are free from errors and sustainable -> high quality

Continuous Delivery - system that facilitates you to make continuous deployment

Cloud - go global in minutes

DevOps solves
CI and CD - 3 ways
Infrastructure Automation
Managing the relationship between Dev and Operations
Failing intelligently

Kubernetes
Ansible
Bash
Management


GIT - manage collaboration of software development
Linux - Everything is Linux
Ansible - automate tasks with operation infrastructure
Terraform - deploy automation in public cloud
Docker/Kubernetes Deploying Cloud
Python - scripting
Jenkins - build and deploy code
Grafana and ELK ensure operations are funning smoothly
	

Source Code Management
	purpose - version control
		a system that keeps records of your changes
		allows for collaborative development
		allows you to know who made what changes and when
		allows you to revert any changes and go back to a previous state

		
	GIT - Distributed Version Control System
		All changes done to a repository are saved by GIT
		Has its own file structure under the hood
		Historical hash to content key is saved for each snapshow 
		Can be used locally without internet connection
		
		Centralized - Remote repo - developers merge code - commit
			If repository goes down or you lose local - always have to be connected to internet
			Bad if centralized repo is lost
				
		Distributed - Must not have internet access to remote repo
			Git -> commit -> local repository
			To share -> push
			Distributed copies, have redundancy
			
		Local
			Working directory - git add - command for repository
			
			Staging Area - git commit -> local repo
			
			Local Repo - git push -> remote repo
			
		Remote Repo - Production Line - Main/Master branch
			Pull
			
			mkdir - <<name>> name it make repository
			cd <<name>>
			git init - creates working directory
			ls -la - list 
			ls -la .git - all directories in git repo
			ls -l
			
						
			git config --list --global
			git config --list --system
			git config --list --local

			git add <filename> - creates a file 
			git add . (all files)
			git commit -m "commit message"
			
      git vi <<filename>> - another way to 
			To get in to the insert mode: press I
			to exit: press esc , shift +:wq
			
			git status - shows files
			
			git rm - deletes file
		
		SHOW DIFF in BRANCHES
			git diff <filename> - shows different versions
		
		VIEW ALL PROGRESS
			git log --all --decorate --oneline --graph
			git log --stat --summary
			git log -p
			git log --oneline
			
			gitk - opens new GUI that show all
			
			git restore --staged <filename>
		
		STASH		
			git stash - saves WIP on feature
			git stash list - show you what is stashed
			git stash apply stash@[0] 
			git stash pop[1] - takes it out of the stash
			
			git stash list - shows you the stash
			git stash pop stash@{0}
			
			git stash clear = will clear all your stashes
			git stash drop stash(1)
			
			git stash show stash@{1}
			
			git stash -u unflagged files (not previously committed)
			git stash -a stash everything
			
		If customer is using a version, create a branch for the development and for the bug to work on new features.
		Once devlopment is commited to branch -> merge into production line (main branch)
		Pull request - ask to review -> must have multiple reviewers (at least 2) ->
			has issues -> reject
			needs work -> comment
			good -> approve
		-> merge to main 
		
		when particular branch only one feature is approved, delete the branch
		when particular branch is needed for more, then keep it
		
		If users report a bug, create a new branch called "app-bug"
		
			git branch branch-name creating a branch
			git switch branch-name - switching to branch
			git branch -d - deletes branch
			git merge branch-name - merges branch into main
			git checkout -b new-branch - creates a new branch and switches to new branch


MERGING TYPES - see commands above
	Fast forward merge: In fast-forward merge, git simply moves the source branch pointer to the target branch pointer without creating an extra merge commit.
	
	Three-way merge: This is a common scenario for large features or when several developers are working on a project simultaneously. 
		If the two branches you're trying to merge both changed the same part of the same file, Git won't be able to figure out which version to use. 
		When such a situation occurs, it stops right before the merge commit so that you can resolve the conflicts manually.  
		will see >>>>> and =========== and the text or code that is conflicting - will have to manually edit
   
GITHUB - Using the remote repository
	push and pull
		command: git push
		command: git pull - accessing the master remote reporsitory
	public and private
		company work would always be private
		
git command to pull master:
	git clone <<url>>
	cd <<url>>
	
Create token
	command push origin main
	
Delete token 
	On github: revoke all tokens
	generate new token
	use token on git
		git push origin main
		
	git remote -v 
		shows files are synced or not
		
	git fetch - get on local repo what is remote
		download files but decide later if you want to merge or not
		
	git branch -r (remote)
	
	git branch -a (local)
	
	git diff origin/main	
		will show changes between remote and local
	
	git merge origin/main
		merges the changes
		
	Steps when changing on Github
	1. edit file and commit on GITHUB
	2. git fetch on local
	3. git status
	4. git branch -r git branch -a 
	5. git diff origin/main
	6. git merge origin/main 
	
	ALWAYS USE GIT STATUS TO SEE IF CHANGES HAVE BEEN MADE.
	
	
	1. create a branch in remote
	2. create the branch at local
	3.integrate local and remote branch
	4. git pull -u origin <<branch-name>>
	5. git push --set -upstream origin <<new-branch-name>>
	6. git puah -u origin <<branch-name>>
